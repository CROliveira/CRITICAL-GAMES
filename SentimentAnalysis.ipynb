{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T23:02:35.058037Z",
     "start_time": "2019-11-18T23:02:33.390634Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T23:02:35.291831Z",
     "start_time": "2019-11-18T23:02:35.061017Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>This quiet , introspective and entertaining in...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Even fans of Ismail Merchant 's work , I suspe...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>A positively thrilling combination of ethnogra...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Aggressive self-glorification and a manipulati...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>A comedy-drama of nearly epic proportions root...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1  \\\n",
       "0  4   \n",
       "1  1   \n",
       "2  3   \n",
       "3  1   \n",
       "4  4   \n",
       "\n",
       "  A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .  \\\n",
       "0  This quiet , introspective and entertaining in...                                                                                                                                             \n",
       "1  Even fans of Ismail Merchant 's work , I suspe...                                                                                                                                             \n",
       "2  A positively thrilling combination of ethnogra...                                                                                                                                             \n",
       "3  Aggressive self-glorification and a manipulati...                                                                                                                                             \n",
       "4  A comedy-drama of nearly epic proportions root...                                                                                                                                             \n",
       "\n",
       "  Unnamed: 2  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "3        NaN  \n",
       "4        NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full = pd.read_fwf(\"full.txt\")\n",
    "full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T23:02:35.322991Z",
     "start_time": "2019-11-18T23:02:35.299175Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>Brando</th>\n",
       "      <th>seems uninspired by the heist script and is phoning</th>\n",
       "      <th>it</th>\n",
       "      <th>in</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Marlon</td>\n",
       "      <td>Brando is incredible as the patriarch of the f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Brando</td>\n",
       "      <td>is Brando , but for this one it 's not enough</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  Brando seems uninspired by the heist script and is phoning  it  in\n",
       "0  4  Marlon  Brando is incredible as the patriarch of the f...  NaN NaN\n",
       "1  1  Brando      is Brando , but for this one it 's not enough  NaN NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiny = pd.read_fwf(\"tiny.txt\")\n",
    "tiny.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T23:02:35.374288Z",
     "start_time": "2019-11-18T23:02:35.329985Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   the\n",
       "0   be\n",
       "1  and\n",
       "2   of\n",
       "3    a\n",
       "4   in"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common = pd.read_fwf(\"most_common_english_words.txt\")\n",
    "most_common.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T23:02:35.402293Z",
     "start_time": "2019-11-18T23:02:35.376922Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4</th>\n",
       "      <th>It 's the kind of movie that , aside from Robert Altman , Spike Lee , the Coen Brothers and a few others , our moviemakers do n't make often enough .</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Williams creates a stunning , Taxi Driver-esqu...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Campbell Scott finds the ideal outlet for his ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Has a certain ghoulish fascination , and gener...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>With its parade of almost perpetually wasted c...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Bolstered by an astonishing voice cast excepti...</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   4  \\\n",
       "0  4   \n",
       "1  3   \n",
       "2  3   \n",
       "3  1   \n",
       "4  3   \n",
       "\n",
       "  It 's the kind of movie that , aside from Robert Altman , Spike Lee , the Coen Brothers and a few others , our moviemakers do n't make often enough .  \\\n",
       "0  Williams creates a stunning , Taxi Driver-esqu...                                                                                                      \n",
       "1  Campbell Scott finds the ideal outlet for his ...                                                                                                      \n",
       "2  Has a certain ghoulish fascination , and gener...                                                                                                      \n",
       "3  With its parade of almost perpetually wasted c...                                                                                                      \n",
       "4  Bolstered by an astonishing voice cast excepti...                                                                                                      \n",
       "\n",
       "  Unnamed: 2  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "3        NaN  \n",
       "4          .  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small = pd.read_fwf(\"small.txt\")\n",
    "small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T23:02:35.435622Z",
     "start_time": "2019-11-18T23:02:35.407624Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4</th>\n",
       "      <th>A must for fans of British cinema , if only because so many titans of the industry are along for the ride .</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>It 's a fine , focused piece of work that reop...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Romantic comedy and Dogme 95 filmmaking may se...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>At a time when we 've learned the hard way jus...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>A fascinating documentary about the long and e...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Rodriguez has the chops of a smart-aleck film ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   4  \\\n",
       "0  4   \n",
       "1  4   \n",
       "2  1   \n",
       "3  4   \n",
       "4  3   \n",
       "\n",
       "  A must for fans of British cinema , if only because so many titans of the industry are along for the ride .  \\\n",
       "0  It 's a fine , focused piece of work that reop...                                                            \n",
       "1  Romantic comedy and Dogme 95 filmmaking may se...                                                            \n",
       "2  At a time when we 've learned the hard way jus...                                                            \n",
       "3  A fascinating documentary about the long and e...                                                            \n",
       "4  Rodriguez has the chops of a smart-aleck film ...                                                            \n",
       "\n",
       "  Unnamed: 2  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "3        NaN  \n",
       "4        NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium = pd.read_fwf(\"medium.txt\")\n",
    "medium.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART I: File I/O, strings, lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T23:02:35.450152Z",
     "start_time": "2019-11-18T23:02:35.439871Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import TextIO, List, Union, Dict, Tuple\n",
    "\n",
    "# PART I: File I/O, strings, lists\n",
    "\n",
    "def is_word(token: str) -> bool:\n",
    "    '''Return True IFF token is an alphabetic word optionally containing\n",
    "    forward slashes or dashes.\n",
    "    \n",
    "    >>> is_word('Amazing')\n",
    "    True\n",
    "    >>> is_word('writer/director')\n",
    "    True\n",
    "    >>> is_word('true-to-life')\n",
    "    True\n",
    "    >>> is_word(\"'re\")\n",
    "    False\n",
    "    >>> is_word(\"1960s\")\n",
    "    False\n",
    "    '''\n",
    "    #need condition that inclues words containing dashes or slashes\n",
    "    #need condition that ignores consistent punctuation\n",
    "    #need condition to exclude apostrophe between letters\n",
    "    clean_token=token.strip('\\n')\n",
    "    if clean_token.isalpha():\n",
    "        return True\n",
    "    elif \"'\" in clean_token:\n",
    "        return False\n",
    "    else:\n",
    "        return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T23:02:35.465384Z",
     "start_time": "2019-11-18T23:02:35.456453Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_word('Amazing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T23:02:35.473554Z",
     "start_time": "2019-11-18T23:02:35.467846Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_word_list(statement: str) -> List[str]:\n",
    "    '''Return a list of words contained in statement, converted to lowercase. \n",
    "    Use is_word to determine whether each token in statement is a word.\n",
    "    \n",
    "    >>> get_word_list('A terrible , 1970s mess of true-crime nonsense from writer/director Shyamalan .')\n",
    "    ['a', 'terrible', 'mess', 'of', 'true-crime', 'nonsense', 'from', 'writer/director', 'shyamalan']\n",
    "    '''\n",
    "    word_list=[]\n",
    "    statement2=statement.split(' ')\n",
    "    for item in statement2:\n",
    "        if is_word(item):\n",
    "            low_item=item.lower()\n",
    "            word_list.append(low_item)\n",
    "    return word_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T23:02:35.484476Z",
     "start_time": "2019-11-18T23:02:35.477058Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'terrible', 'mess', 'of', 'nonsense', 'from', 'shyamalan']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_list('A terrible , 1970s mess of true-crime nonsense from writer/director Shyamalan .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T23:02:35.496964Z",
     "start_time": "2019-11-18T23:02:35.490923Z"
    }
   },
   "outputs": [],
   "source": [
    "def judge(score: float) -> str:\n",
    "    '''Return 'negative' if score is 1.5 or less.\n",
    "    Return 'positive' if score is 2.5 or more.\n",
    "    Return 'neutral' otherwise.\n",
    "    >>> judge(1.3)\n",
    "    'negative'\n",
    "    >>> judge(1.8)\n",
    "    'neutral'\n",
    "    >>> judge(3.4)\n",
    "    'positive'\n",
    "    '''\n",
    "    if score <= 1.5:\n",
    "        return 'negative'\n",
    "    elif score >= 2.5:\n",
    "        return 'positive'\n",
    "    else:\n",
    "        return 'neutral'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T23:02:35.508574Z",
     "start_time": "2019-11-18T23:02:35.501293Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neutral'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "judge(1.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T23:02:35.523202Z",
     "start_time": "2019-11-18T23:02:35.511823Z"
    }
   },
   "outputs": [],
   "source": [
    "def word_kss_scan(word: str, file: TextIO) -> Union[None, float]:\n",
    "    '''Given file composed of rated movie reviews, return the average score\n",
    "    of all occurrences of word in file. If word does not occur in file, return None.\n",
    "    [examples not required]\n",
    "    '''\n",
    "    #convert string score into integer score\n",
    "    #how many times did i see the word\n",
    "    seen=0\n",
    "    score=0\n",
    "    for line in file:\n",
    "        rate=int(line[0])\n",
    "        word_list=get_word_list(line)\n",
    "        for item in word_list:\n",
    "            #assign score of review to word, if word in review\n",
    "            if item==word:\n",
    "                score+=rate\n",
    "                seen+=1\n",
    "    if seen!=0:\n",
    "        return score/seen\n",
    "    else:\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Dictionnaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T23:02:35.540027Z",
     "start_time": "2019-11-18T23:02:35.527761Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_kss(file: TextIO) -> Dict[str, List[int]]:\n",
    "    '''Given file composed of rated movie reviews, return a dictionary\n",
    "    containing all words in file as keys. For each key, store a list\n",
    "    containing the total sum of review scores and the number of times\n",
    "    the key has occurred as a value, e.g., { 'a' : [12, 4] }\n",
    "    [examples not required]\n",
    "    \n",
    "    '''\n",
    "    # accumulate per line, per word\n",
    "    # rate needs to be added\n",
    "    # create extracted_dict={}\n",
    "    extracted_dict={}\n",
    "    \n",
    "    for line in file.readlines(): \n",
    "        rate = int(line.split(\" \", 1)[0]) # separate each line into two parts, first part is the integer rate\n",
    "        word_list = get_word_list(line.split(\" \", 1)[1].strip(\"\\n\")) \n",
    "        # second part is the list of words in lowercase\n",
    "        for word in word_list:\n",
    "            if word in extracted_dict:\n",
    "                extracted_dict[word_list][0] += rate\n",
    "                extracted_dict[word_list][1] += 1\n",
    "            else:\n",
    "                extracted_dict[word] = [rate, 1]\n",
    "                \n",
    "    return extracted_dict\n",
    "    #add items to extracted_dict: {extracted_dict[word][0] = rate, extracted_dict[word][1] = word}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T23:02:35.554720Z",
     "start_time": "2019-11-18T23:02:35.542648Z"
    }
   },
   "outputs": [],
   "source": [
    "def word_kss(word: str, kss: Dict[str, List[int]]) -> Union[float, None]:\n",
    "    '''Return the Known Sentiment Score of word if it appears in kss. \n",
    "    If word does not appear in kss, return None.\n",
    "    [examples not required]\n",
    "    '''\n",
    "    word = word.lower()\n",
    "    if word in kss:\n",
    "        return float(kss[word][0] / kss[word][1])\n",
    "    return None\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T23:02:35.572275Z",
     "start_time": "2019-11-18T23:02:35.561562Z"
    }
   },
   "outputs": [],
   "source": [
    "def statement_pss(statement: str, kss: Dict[str, List[int]]) -> Union[float, None]:\n",
    "    '''Return the Predicted Sentiment Score of statement based on\n",
    "    word Known Sentiment Scores from kss.\n",
    "    Return None if statement contains no words from kss.'''\n",
    "    #uses get_word_list\n",
    "    word_list = get_word_list(statement)\n",
    "    word_rate = 0.0\n",
    "    counter = 0\n",
    "    for item in word_list:\n",
    "        if item in kss:\n",
    "            word_rate += (kss[item][0] / kss[item][1])\n",
    "            counter += 1\n",
    "    if counter == 0:\n",
    "        return None\n",
    "    return word_rate / counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART III: Word Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T23:02:53.831392Z",
     "start_time": "2019-11-18T23:02:53.825254Z"
    }
   },
   "outputs": [],
   "source": [
    "def score(item: Tuple[str, List[int]]) -> float:\n",
    "    '''Given item as a (key, value) tuple, return the\n",
    "    ratio of the first and second integer in value\n",
    "    '''\n",
    "    \n",
    "    return item[1][0] / item[1][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T01:49:15.412421Z",
     "start_time": "2019-11-19T01:49:15.378790Z"
    }
   },
   "outputs": [],
   "source": [
    "def most_extreme_words(count, min_occ, kss, pos):\n",
    "    '''Return a list of lists containing the count most extreme words\n",
    "    that occur at least min_occ times in kss.\n",
    "    Each item in the list is formatted as follows:\n",
    "    [word, average score, number of occurrences]\n",
    "    If pos is True, return the most positive words.\n",
    "    If pos is False, return the most negative words.\n",
    "    [examples not required]\n",
    "    '''\n",
    "    res = []\n",
    "    temp_dict = {}\n",
    "    \n",
    "    for key, value in list(kss.items()):\n",
    "        if value[1] >= min_occ:\n",
    "            temp_dict[key] = value[:]\n",
    "            \n",
    "    sorted_list = sorted(temp_dict.items(), key=score, reverse=pos)[:count]\n",
    "    \n",
    "    for item in sorted_list:\n",
    "        res.append([item[0], score(item), item[1][1]])\n",
    "    \n",
    "    \n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T23:02:35.617496Z",
     "start_time": "2019-11-18T23:02:35.606603Z"
    }
   },
   "outputs": [],
   "source": [
    "def most_negative_words(count, min_occ, kss):\n",
    "    '''Return a list of the count most negative words that occur at least min_occ times in kss.\n",
    "    '''\n",
    "    \n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T23:02:36.096386Z",
     "start_time": "2019-11-18T23:02:35.624249Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-194656a69190>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tiny.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_kss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-33996a4801f2>\u001b[0m in \u001b[0;36mextract_kss\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mextracted_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0mextracted_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0mextracted_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "# Pick a dataset    \n",
    "    dataset = 'tiny.txt'\n",
    "    #dataset = 'small.txt'\n",
    "    #dataset = 'medium.txt'\n",
    "    #dataset = 'full.txt'\n",
    "    \n",
    "    with open('tiny.txt','r') as file:\n",
    "        print(extract_kss(file))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T23:02:36.100624Z",
     "start_time": "2019-11-18T23:02:33.465Z"
    }
   },
   "outputs": [],
   "source": [
    "d = {}\n",
    "d[2] = 'coffee'\n",
    "d[15] = 'juice'\n",
    "d[7] = 'coffee'\n",
    "d[5] = 'donuts'\n",
    "d[9] = 'cake'\n",
    "d[10] = 'balloons'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T23:02:36.102797Z",
     "start_time": "2019-11-18T23:02:33.468Z"
    }
   },
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T23:02:36.104796Z",
     "start_time": "2019-11-18T23:02:33.470Z"
    }
   },
   "outputs": [],
   "source": [
    "def reverse_lookup_lists(phone_num, phone_numbers, names):\n",
    "    \"\"\" (str, list of str, list of str) -> str\n",
    "\n",
    "    Precondition: len(phone_numbers) == len(names)\n",
    "\n",
    "    This function receives a phone number phone_num, and two lists: a list of \n",
    "    phone numbers phone_numbers and a list of names names.  These lists are\n",
    "    parallel lists, so the name in position 0 of the names list is \n",
    "    associated with the phone number in position 0 of the phone_numbers \n",
    "    list, and so on.\n",
    "\n",
    "    Return the name associated with phone_num according to phone_numbers\n",
    "    and names, or an empty string if there is no match.\n",
    "    \n",
    "    >>> reverse_lookup_lists('416-555-6543', ['416-555-3498', \\\n",
    "        '647-555-9812', '416-555-6543', '905-555-6681'], ['John A. Macdonald', \\\n",
    "        'Louis Riel', 'Canoe Head', 'Tim Horton'])        \n",
    "    'Canoe Head'\n",
    "    \"\"\"\n",
    "    res_str = \"\"\n",
    "    for i in range(len(phone_numbers)):\n",
    "        if phone_num == phone_numbers[i]:\n",
    "            res_str = names[i]\n",
    "    return res_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T23:02:36.107638Z",
     "start_time": "2019-11-18T23:02:33.473Z"
    }
   },
   "outputs": [],
   "source": [
    "reverse_lookup_lists('416-555-6543', ['416-555-3498', \\\n",
    "        '647-555-9812', '416-555-6543', '905-555-6681'], ['John A. Macdonald', \\\n",
    "        'Louis Riel', 'Canoe Head', 'Tim Horton'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T23:02:36.109784Z",
     "start_time": "2019-11-18T23:02:33.475Z"
    }
   },
   "outputs": [],
   "source": [
    "def reverse_lookup_dictionary(phone_num, phone_to_name):\n",
    "    \"\"\" (str, dict of {str: str}) -> str\n",
    "\n",
    "    This function receives a phone number phone_num, and a dictionary\n",
    "    phone_to_name in which each key is a phone number and each value\n",
    "    is the name associated with that phone number.\n",
    "\t\n",
    "    Return the name associated with phone_num in phone_to_name, or\n",
    "    an empty string if there is no match.\n",
    "    \n",
    "    >>> reverse_lookup_dictionary(\"416-555-3498\", {\"416-555-3498\": \\\n",
    "        \"John A. Macdonald\", \"647-555-9812\": \"Louis Riel\", \"416-555-6543\": \\\n",
    "        \"Canoe Head\", \"905-555-6681\":\"Tim Horton\"})\n",
    "    'John A. Macdonald'        \n",
    "    \"\"\"\n",
    "    if phone_num in phone_to_name:\n",
    "        return phone_to_name[phone_num]\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T23:02:36.111799Z",
     "start_time": "2019-11-18T23:02:33.479Z"
    }
   },
   "outputs": [],
   "source": [
    "reverse_lookup_dictionary(\"416-555-3498\", {\"416-555-3498\": \\\n",
    "        \"John A. Macdonald\", \"647-555-9812\": \"Louis Riel\", \"416-555-6543\": \\\n",
    "        \"Canoe Head\", \"905-555-6681\":\"Tim Horton\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T23:02:36.115096Z",
     "start_time": "2019-11-18T23:02:33.481Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_quantities(table_to_foods):\n",
    "    \"\"\" (dict of {str: list of str}) -> dict of {str: int}\n",
    "\t\n",
    "    The table_to_foods dict has table names as keys (e.g., 't1', 't2', and so on) and each value\n",
    "    is a list of foods ordered for that table.\n",
    "\n",
    "    Return a dictionary where each key is a food from table_to_foods and each\n",
    "    value is the quantity of that food that was ordered.\n",
    "\t\n",
    "    >>> get_quantities({'t1': ['Vegetarian stew', 'Poutine', 'Vegetarian stew'], 't3': ['Steak pie', 'Poutine', 'Vegetarian stew'], 't4': ['Steak pie', 'Steak pie']})\n",
    "    {'Vegetarian stew': 3, 'Poutine': 2, 'Steak pie': 3}\t\n",
    "    \"\"\"\n",
    "\n",
    "    food_to_quantity = {}\n",
    "    # Accumulate the food information here.\n",
    "    for table_order in table_to_foods.values():\n",
    "        for menu_item in table_order:\n",
    "            if menu_item in food_to_quantity:\n",
    "                food_to_quantity[menu_item] += 1 \n",
    "            else:\n",
    "                food_to_quantity[menu_item] = 1\n",
    "\n",
    "    return food_to_quantity\n",
    "\n",
    "get_quantities({'t1': ['Vegetarian stew', 'Poutine', 'Vegetarian stew'], 't3': ['Steak pie', 'Poutine', 'Vegetarian stew'], 't4': ['Steak pie', 'Steak pie']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T23:02:36.118783Z",
     "start_time": "2019-11-18T23:02:33.483Z"
    }
   },
   "outputs": [],
   "source": [
    "get_quantities({'t1': ['Vegetarian stew', 'Poutine', 'Vegetarian stew'], 't3': ['Steak pie', 'Poutine', 'Vegetarian stew'], 't4': ['Steak pie', 'Steak pie']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T23:02:36.122369Z",
     "start_time": "2019-11-18T23:02:33.486Z"
    }
   },
   "outputs": [],
   "source": [
    "def Average(lst): \n",
    "    return sum(lst) / len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T23:02:36.125532Z",
     "start_time": "2019-11-18T23:02:33.491Z"
    }
   },
   "outputs": [],
   "source": [
    "lst = [1,2,3] \n",
    "average = Average(lst) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T23:02:36.131963Z",
     "start_time": "2019-11-18T23:02:33.494Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Average of the list =\", round(average, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T23:02:36.137375Z",
     "start_time": "2019-11-18T23:02:33.496Z"
    }
   },
   "outputs": [],
   "source": [
    "dir(tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T19:06:09.864174Z",
     "start_time": "2019-11-21T19:06:09.792846Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "8\n",
      "9\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "for x in range(2,4):\n",
    "    y=2\n",
    "    while y < 4:\n",
    "        print(x**y)\n",
    "        y+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
